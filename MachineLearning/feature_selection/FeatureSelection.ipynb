{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "---\n",
    "\n",
    "#### Overfitting Bug\n",
    "\n",
    "This bug was found when Katie was trying to make an overfit decision tree to use as an example in the decision tree mini-project. A decision tree is classically an algorithm that can be easy to overfit; one of the easiest ways to get an overfit decision tree is to use a small training set and lots of features\n",
    "\n",
    "- ao fazer o **treinamento**, parece que encontrei a solução para tudo e a **accuracy** fica enorme\n",
    "\n",
    "- ao **testar** os dados, minha **accuracy** acaba ficando abaixo do esperado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy\n",
    "numpy.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words (features) and authors (labels), already largely processed\n",
    "\n",
    "These files should have been created from the previous (Lesson 10) mini-project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_file = \"c:/pyprog/udamini/text_learning/your_word_data.pkl\" \n",
    "authors_file = \"c:/pyprog/udamini/text_learning/your_email_authors.pkl\"\n",
    "word_data = pickle.load(open(words_file, \"r\"))\n",
    "authors = pickle.load(open(authors_file, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test_size is the percentage of events assigned to the test set (the remainder go into training)\n",
    "\n",
    "- feature matrices changed to dense representations for compatibility with classifier functions in versions 0.15.2 and earlier\n",
    "\n",
    "Observe o erro aqui:\n",
    "\n",
    "- eu defini um conjunto muito **pequeno de dados** e **menor ainda** para dados de teste, serão apenas 15 dados de teste ao todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(word_data, \n",
    "                                                                            authors, test_size=0.1, random_state=42)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')\n",
    "features_train = vectorizer.fit_transform(features_train)\n",
    "features_test  = vectorizer.transform(features_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a classic way to overfit is to use a small number of data points and a large number of features\n",
    "\n",
    "- train on only 150 events to put ourselves in this regime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = features_train[:150].toarray()\n",
    "labels_train   = labels_train[:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier here\n",
    "\n",
    "- observe o valor elevado demais para minha acuidade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy of Model: 81.684 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(features_train, labels_train)\n",
    "from sklearn import tree\n",
    "\n",
    "accuracy = dt.score(features_test, labels_test)\n",
    "print(\"\\n Accuracy of Model: %0.3F %%\" % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the top feature in the decision tree and its relative importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Value of most important feature: 0.3636 \n",
      "\n",
      " Number of most important feature: 21323 \n"
     ]
    }
   ],
   "source": [
    "top_feature = dt.feature_importances_[dt.feature_importances_ > 0.2]\n",
    "\n",
    "import numpy as np\n",
    "idx = np.where(dt.feature_importances_ > 0.2)\n",
    "\n",
    "print(\"\\n Value of most important feature: %0.4F \" % top_feature)\n",
    "print(\"\\n Number of most important feature: %0.0F \" % idx[0][0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outro modo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21323 0.36363636363636365\n",
      "Feature Ranking: \n",
      "1 feature no.21323 (0.363636363636)\n",
      "2 feature no.18849 (0.186927243449)\n",
      "3 feature no.11975 (0.105378579003)\n",
      "4 feature no.22546 (0.0840692099229)\n",
      "5 feature no.29690 (0.0675805258904)\n",
      "6 feature no.16267 (0.0474074074074)\n",
      "7 feature no.15331 (0.0426666666667)\n",
      "8 feature no.16440 (0.0262801932367)\n",
      "9 feature no.37406 (0.0255293305728)\n",
      "10 feature no.15560 (0.0248101945003)\n"
     ]
    }
   ],
   "source": [
    "importances = dt.feature_importances_\n",
    "for index, item in enumerate(importances):\n",
    "    if item > 0.2:        \n",
    "        print index, item       \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print 'Feature Ranking: '\n",
    "for i in range(10):\n",
    "    print \"{} feature no.{} ({})\".format(i+1,indices[i],importances[indices[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sshacklsims1rcsntxswbellnet\n"
     ]
    }
   ],
   "source": [
    "feature_name = vectorizer.get_feature_names()\n",
    "for index, item in enumerate(feature_name):\n",
    "    if index == 33614:        \n",
    "        print item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the word that is causing the trouble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Word causing most discrimination on the decision tree: houectect\n"
     ]
    }
   ],
   "source": [
    "vocab_list = vectorizer.get_feature_names()\n",
    "print(\"\\n Word causing most discrimination on the decision tree: %s\" % vocab_list[idx[0][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Special Note\n",
    "\n",
    "Depending on when you downloaded the code provided for find_signature.py, you may need to change the code in lines 9-10 to be so that the files created from running vectorize_text.py are reflected properly\n",
    "\n",
    "        words_file = \"../text_learning/your_word_data.pkl\"\n",
    "        \n",
    "        authors_file = \"../text_learning/your_email_authors.pkl\"\n",
    "        \n",
    "        \n",
    "In addition, if you are having trouble getting the code to run due to memory issues, then if you are on version 0.16.x of scikit-learn, you can remove the **.toarray()** function from the line where features_train is created to save on memory - the decision tree classifier can, in that version take as input a sparse array instead of only dense arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Take your (overfit) decision tree and use the feature_importances_ attribute to get a list of the relative importance of all the features being used\n",
    "\n",
    "We suggest iterating through this list (it’s long, since this is text data) and only printing out the feature importance if it’s above some threshold (say, 0.2--remember, if all words were equally important, each one would give an importance of far less than 0.01)\n",
    "\n",
    "What’s the importance of the most important feature? What is the number of this feature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In order to figure out what words are causing the problem, you need to go back to the TfIdf and use the feature numbers that you obtained in the previous part of the mini-project to get the associated words\n",
    "\n",
    "You can return a list of all the words in the TfIdf by calling **get_feature_names()** on it; pull out the word that’s causing most of the discrimination of the decision tree\n",
    "\n",
    "What is it? Does it make sense as a word that’s uniquely tied to either Chris Germany or Sara Shackleton, a signature of sorts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This word seems like an outlier in a certain sense, so let’s remove it and refit. Go back to text_learning/vectorize_text.py, and remove this word from the emails using the same method you used to remove “sara”, “chris”, etc\n",
    "\n",
    "Rerun vectorize_text.py, and once that finishes, rerun find_signature.py\n",
    "\n",
    "Any other outliers pop up? What word is it? Seem like a signature-type word?\n",
    "\n",
    "*Define an outlier as a feature with importance >0.2, as before*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Update vectorize_test.py one more time, and rerun. Then run find_signature.py again\n",
    "\n",
    "Any other important features (importance>0.2) arise? How many?\n",
    "\n",
    "Do any of them look like “signature words”, or are they more “email content” words, that look like they legitimately come from the text of the messages?\n",
    "\n",
    "R: **houectect**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many training points are there, according to the starter code?\n",
    "len(features_train)\n",
    "\n",
    "# What’s the importance of the most important feature? What is the number of this feature?\n",
    "importances = clf.feature_importances_\n",
    "for index, item in enumerate(importances):\n",
    "    if item > 0.2:        \n",
    "        print index, item       \n",
    "       \n",
    "import numpy as np\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print 'Feature Ranking: '\n",
    "for i in range(10):\n",
    "    print \"{} feature no.{} ({})\".format(i+1,indices[i],importances[indices[i]])\n",
    "\n",
    "#remove this words from the emails using the same method you used to remove “sara”, “chris”, etc    \n",
    "    \n",
    "# What’s the most powerful word when your decision tree is makeing its classification decisions?\n",
    "feature_name = vectorizer.get_feature_names()\n",
    "for index, item in enumerate(feature_name):\n",
    "    if index == 33614:        \n",
    "        print item\n",
    "\n",
    "vectorizer.get_feature_names()[33614]\n",
    "# Result: sshacklensf #palavra exclusiva e fortemente indicativa do autor      \n",
    "        \n",
    "feature_name = vectorizer.get_feature_names()\n",
    "for index, item in enumerate(feature_name):\n",
    "    if index == 14343:        \n",
    "        print item \n",
    "        \n",
    "vectorizer.get_feature_names()[14343]\n",
    "# Result: cgermannsf\n",
    "        \n",
    "feature_name = vectorizer.get_feature_names()\n",
    "for index, item in enumerate(feature_name):\n",
    "    if index == 14343:        \n",
    "        print item \n",
    "# Result: houectect\n",
    "\n",
    "#sklearn.feature_extraction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
