{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "---\n",
    "\n",
    "Starter code for the validation mini-project\n",
    "\n",
    "The first step toward building your POI identifier!\n",
    "\n",
    "Start by loading/formatting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "sys.path.append(\"c:/pyprog/udamini/tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "data_dict = pickle.load(open(\"c:/pyprog/udamini/final_project/final_project_dataset.pkl\", \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First element is our labels, any added elements are predictor features\n",
    "\n",
    "Keep this the same for the mini-project, but you'll have a different feature list when you do the final project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = [\"poi\", \"salary\"]\n",
    "\n",
    "data = featureFormat(data_dict, features_list)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's all yours from here forward!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sem o Cross Validation (treino e testo com os mesmos dados) dá **overfitting**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores :0.989473684211\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(features, labels)\n",
    "\n",
    "teste = clf.score(features, labels)\n",
    "print ('Scores :{}'.format(teste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- com o Cross Validation, o meu resultado é bem mais realista:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores :0.724137931034\n"
     ]
    }
   ],
   "source": [
    "#from sklearn import cross_validation\n",
    "from sklearn import model_selection\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = model_selection.train_test_split(\n",
    "                                             features, labels, test_size=0.3, random_state=42)\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "\n",
    "teste = clf.score(features_test, labels_test)\n",
    "print ('Scores :{}'.format(teste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra maneira de tirar a **accuracy**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7241379310344828\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred = clf.predict(features_test)\n",
    "print \"accuracy:\", accuracy_score(labels_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "You’ll start by building the simplest imaginable (unvalidated) POI identifier. The starter code (validation/validate_poi.py) for this lesson is pretty bare:\n",
    "\n",
    "- all it does is read in the data, and format it into lists of labels and features\n",
    "\n",
    "Create a decision tree classifier (just use the default parameters), train it on all the data (you will fix this in the next part!), and print out the accuracy. **This is an overfit tree, do not thrust this number!** \n",
    "\n",
    "Nonetheless, what’s the accuracy?\n",
    "\n",
    "From Python 3.3 forward, a change to the order in which dictionary keys are processed was made such that the orders are randomized each time the code is run. This will cause some compatibility problems with the graders and project code, which were run under Python 2.7. To correct for this, add the following argument to the featureFormat call on line 25 of validate_poi.py:\n",
    "\n",
    "        sort_keys = '../tools/python2_lesson13_keys.pkl'\n",
    "\n",
    "This will open up a file in the tools folder with the Python 2 key order\n",
    "\n",
    "*Note: If you are not getting the results expected by the grader, then you may want to check the file tools/feature_format.py. Due to changes in the final project, some file changes have affected the numbers output on this assignment as written. Check that you have the most recent version of the file from the repository, such that the featureFormat has a default parameter for **sort_keys = False** and that **keys = dictionary.keys()** result*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now you’ll add in training and testing, so that you get a trustworthy accuracy number\n",
    "\n",
    "Use the train_test_split validation available in sklearn.cross_validation; hold out 30% of the data for testing and set the **random_state parameter** to **42** (random_state controls which points go into the training set and which are used for testing; setting it to 42 means we know exactly which events are in which set, and can check the results you get)\n",
    "\n",
    "What’s your updated accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Observe que vc deve usar o par de **teste** (X_test, y_test) para calcular o _score_, conforme preconiza a documentação.\n",
    "\n",
    "        score(X, y, sample_weight=None)[source]\n",
    "\n",
    "Returns the mean accuracy on the given test data and labels\n",
    "\n",
    "In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted\n",
    "\n",
    "Parameters:    \n",
    "        \n",
    "        X : array-like, shape = (n_samples, >n_features)\n",
    "\n",
    "Test samples\n",
    "\n",
    "        y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
    "\n",
    "True labels for X\n",
    "\n",
    "        sample_weight : array-like, shape = [n_samples], optional\n",
    "\n",
    "Sample weights returns:    \n",
    "\n",
    "        score : float\n",
    "\n",
    "        Mean accuracy of self.predict(X) wrt. y.\n",
    "\n",
    "[aqui](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
